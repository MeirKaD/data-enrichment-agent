{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Powered Data Enrichment Agent\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates building an intelligent data enrichment agent using:\n",
    "\n",
    "- **LangGraph**: Agentic workflow orchestration\n",
    "- **Bright Data MCP**: Model Context Protocol integration for web data access\n",
    "- **Claude Sonnet 4**: Advanced reasoning and structured extraction\n",
    "\n",
    "### What This Agent Does\n",
    "\n",
    "1. Takes a research topic and JSON schema as input\n",
    "2. Autonomously searches the web using Bright Data's SERP API\n",
    "3. Scrapes relevant websites with anti-bot bypass\n",
    "4. Extracts and structures data matching your schema\n",
    "5. Returns validated JSON output\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langgraph langchain-openai langchain-mcp-adapters python-dotenv nest-asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Environment Variables\n",
    "\n",
    "**For Google Colab:**\n",
    "```python\n",
    "from google.colab import userdata\n",
    "import os\n",
    "os.environ['BRIGHT_DATA_API_KEY'] = userdata.get('BRIGHT_DATA_API_KEY')\n",
    "os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
    "```\n",
    "\n",
    "**For local Jupyter:**\n",
    "Use the cell below with .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if running in Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "    os.environ['BRIGHT_DATA_API_KEY'] = userdata.get('BRIGHT_DATA_API_KEY')\n",
    "    os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
    "    print(\"âœ“ Loaded keys from Colab secrets\")\n",
    "else:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    print(\"âœ“ Loaded keys from .env file\")\n",
    "\n",
    "# Verify keys are set\n",
    "assert os.getenv(\"BRIGHT_DATA_API_KEY\"), \"BRIGHT_DATA_API_KEY not set\"\n",
    "assert os.getenv(\"ANTHROPIC_API_KEY\"), \"ANTHROPIC_API_KEY not set\"\n",
    "\n",
    "print(\"âœ“ Environment configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Async Event Loop (Required for Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"âœ“ Async event loop configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppress Verbose Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Suppress MCP notification validation warnings\n",
    "logging.getLogger().addFilter(\n",
    "    lambda record: \"Failed to validate notification\" not in record.getMessage()\n",
    ")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Failed to validate notification.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "print(\"âœ“ Logging configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Agent Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Agent State\n",
    "\n",
    "The state tracks:\n",
    "- Research topic\n",
    "- Target extraction schema\n",
    "- Conversation messages\n",
    "- Extracted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Annotated, List, Optional\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "@dataclass\n",
    "class AgentState:\n",
    "    \"\"\"State for the enrichment agent.\"\"\"\n",
    "    topic: str\n",
    "    extraction_schema: dict[str, Any]\n",
    "    messages: Annotated[List[BaseMessage], add_messages] = field(default_factory=list)\n",
    "    info: Optional[dict[str, Any]] = None\n",
    "\n",
    "print(\"âœ“ Agent state defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. System Prompt\n",
    "\n",
    "Instructs the agent on its research capabilities and workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a research agent. Your task is to gather information about a topic and extract structured data.\n",
    "\n",
    "You have access to these tools:\n",
    "- search_engine: Search the web for information (Google/Bing/Yandex)\n",
    "- scrape_as_markdown: Get content from a specific URL with bot detection bypass\n",
    "- web_data_* tools: Fast, reliable structured data extraction from major platforms\n",
    "- submit_info: Call this when you have gathered all the required information\n",
    "\n",
    "Research topic: {topic}\n",
    "\n",
    "Required information schema:\n",
    "{schema}\n",
    "\n",
    "Search for relevant information, scrape important pages, then call submit_info with the extracted data.\"\"\"\n",
    "\n",
    "print(\"âœ“ System prompt configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create the Agent Graph\n",
    "\n",
    "This builds the LangGraph workflow with:\n",
    "- MCP client connection to Bright Data\n",
    "- Claude LLM integration\n",
    "- Tool execution node\n",
    "- Conditional routing logic\n",
    "- **Enhanced error handling for debugging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "async def create_agent():\n",
    "    \"\"\"Create the enrichment agent graph.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Configure MCP client\n",
    "        print(\"Connecting to Bright Data MCP...\")\n",
    "        client = MultiServerMCPClient({\n",
    "            \"bright_data\": {\n",
    "                \"url\": f\"https://mcp.brightdata.com/sse?token={os.getenv('BRIGHT_DATA_API_KEY')}\",\n",
    "                \"transport\": \"sse\",\n",
    "            }\n",
    "        })\n",
    "\n",
    "        # Get available tools from MCP\n",
    "        print(\"Fetching available tools...\")\n",
    "        tools = await client.get_tools()\n",
    "        print(f\"âœ“ Connected to Bright Data MCP ({len(tools)} tools available)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error connecting to MCP:\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        \n",
    "        # Try to extract more details from ExceptionGroup\n",
    "        if hasattr(e, 'exceptions'):\n",
    "            print(f\"\\nSub-exceptions ({len(e.exceptions)} total):\")\n",
    "            for i, sub_exc in enumerate(e.exceptions, 1):\n",
    "                print(f\"  {i}. {type(sub_exc).__name__}: {str(sub_exc)}\")\n",
    "        \n",
    "        raise\n",
    "\n",
    "    # Initialize the model\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "        openai_api_base=\"https://api.anthropic.com/v1\",\n",
    "        model_name=\"claude-sonnet-4-20250514\"\n",
    "    )\n",
    "\n",
    "    async def call_model(state: AgentState) -> dict:\n",
    "        \"\"\"Call the LLM to decide next action.\"\"\"\n",
    "        prompt = SYSTEM_PROMPT.format(\n",
    "            topic=state.topic,\n",
    "            schema=json.dumps(state.extraction_schema, indent=2)\n",
    "        )\n",
    "\n",
    "        # Build messages: system prompt as first human message, then conversation\n",
    "        messages = [HumanMessage(content=prompt)] + list(state.messages)\n",
    "\n",
    "        # Create dynamic submit_info tool based on schema\n",
    "        info_tool = {\n",
    "            \"name\": \"submit_info\",\n",
    "            \"description\": \"Submit the extracted information when done researching. Call this with the structured data matching the required schema.\",\n",
    "            \"parameters\": state.extraction_schema,\n",
    "        }\n",
    "\n",
    "        # Bind all tools including the dynamic info tool\n",
    "        model = llm.bind_tools(list(tools) + [info_tool])\n",
    "\n",
    "        response = await model.ainvoke(messages)\n",
    "\n",
    "        # Check if submitting info\n",
    "        info = None\n",
    "        if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "            for tc in response.tool_calls:\n",
    "                if tc[\"name\"] == \"submit_info\":\n",
    "                    info = tc[\"args\"]\n",
    "                    break\n",
    "\n",
    "        return {\"messages\": [response], \"info\": info}\n",
    "\n",
    "    def route(state: AgentState) -> str:\n",
    "        \"\"\"Route to next node based on last message.\"\"\"\n",
    "        # If we have extracted info, we're done\n",
    "        if state.info:\n",
    "            return \"__end__\"\n",
    "\n",
    "        # Check the last message\n",
    "        if not state.messages:\n",
    "            return \"agent\"\n",
    "\n",
    "        last_msg = state.messages[-1]\n",
    "\n",
    "        if isinstance(last_msg, AIMessage) and hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "            # Check if it's a submit_info call\n",
    "            for tc in last_msg.tool_calls:\n",
    "                if tc[\"name\"] == \"submit_info\":\n",
    "                    return \"__end__\"\n",
    "            # Otherwise, execute the tools\n",
    "            return \"tools\"\n",
    "\n",
    "        return \"agent\"\n",
    "\n",
    "    # Build graph\n",
    "    graph = StateGraph(AgentState)\n",
    "    graph.add_node(\"agent\", call_model)\n",
    "    graph.add_node(\"tools\", ToolNode(tools))\n",
    "    graph.add_edge(\"__start__\", \"agent\")\n",
    "    graph.add_conditional_edges(\"agent\", route)\n",
    "    graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    return graph.compile()\n",
    "\n",
    "print(\"âœ“ Agent graph builder defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Enrichment Function\n",
    "\n",
    "Simple API to run the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def enrich(topic: str, schema: dict) -> dict:\n",
    "    \"\"\"Run the enrichment agent.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Starting enrichment for: {topic}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    agent = await create_agent()\n",
    "    result = await agent.ainvoke({\n",
    "        \"topic\": topic,\n",
    "        \"extraction_schema\": schema,\n",
    "    })\n",
    "    return result.get(\"info\", {})\n",
    "\n",
    "print(\"âœ“ Enrichment function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo: Extract Company Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Extraction Schema\n",
    "\n",
    "Specify exactly what information you want to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"company_name\": {\"type\": \"string\"},\n",
    "        \"industry\": {\"type\": \"string\"},\n",
    "        \"headquarters\": {\"type\": \"string\"},\n",
    "        \"founded\": {\"type\": \"string\"},\n",
    "        \"key_products\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "    },\n",
    "    \"required\": [\"company_name\", \"industry\"]\n",
    "}\n",
    "\n",
    "print(\"Schema defined:\")\n",
    "print(json.dumps(company_schema, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Agent\n",
    "\n",
    "Watch the agent autonomously research and extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await enrich(\"Stripe payments company\", company_schema)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTED INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Competitor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitor_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"competitors\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"market_position\": {\"type\": \"string\"},\n",
    "                    \"key_differentiator\": {\"type\": \"string\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"competitors\"]\n",
    "}\n",
    "\n",
    "result = await enrich(\"Stripe competitors in payment processing\", competitor_schema)\n",
    "\n",
    "print(\"\\nCompetitor Analysis:\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Product Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"product_name\": {\"type\": \"string\"},\n",
    "        \"category\": {\"type\": \"string\"},\n",
    "        \"key_features\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"pricing_model\": {\"type\": \"string\"},\n",
    "        \"target_audience\": {\"type\": \"string\"}\n",
    "    },\n",
    "    \"required\": [\"product_name\", \"category\"]\n",
    "}\n",
    "\n",
    "result = await enrich(\"Claude AI by Anthropic\", product_schema)\n",
    "\n",
    "print(\"\\nProduct Information:\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Common Issues in Google Colab\n",
    "\n",
    "1. **ExceptionGroup errors**: Make sure you installed `nest-asyncio` and ran the async configuration cell\n",
    "2. **API Key errors**: Verify your secrets are properly set in Colab (ğŸ”‘ icon in left sidebar)\n",
    "3. **Connection timeout**: Check your API keys are valid and have proper permissions\n",
    "\n",
    "### Debug Connection\n",
    "\n",
    "Run this cell to test the MCP connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_connection():\n",
    "    \"\"\"Test MCP connection and list available tools.\"\"\"\n",
    "    try:\n",
    "        print(\"Testing MCP connection...\")\n",
    "        client = MultiServerMCPClient({\n",
    "            \"bright_data\": {\n",
    "                \"url\": f\"https://mcp.brightdata.com/sse?token={os.getenv('BRIGHT_DATA_API_KEY')}\",\n",
    "                \"transport\": \"sse\",\n",
    "            }\n",
    "        })\n",
    "        \n",
    "        tools = await client.get_tools()\n",
    "        print(f\"\\nâœ“ Success! Connected to Bright Data MCP\")\n",
    "        print(f\"\\nAvailable tools ({len(tools)}):\")\n",
    "        for tool in tools[:10]:  # Show first 10\n",
    "            print(f\"  - {tool.name}\")\n",
    "        if len(tools) > 10:\n",
    "            print(f\"  ... and {len(tools) - 10} more\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Connection failed\")\n",
    "        print(f\"Error: {type(e).__name__}\")\n",
    "        if hasattr(e, 'exceptions'):\n",
    "            for sub_exc in e.exceptions:\n",
    "                print(f\"  â†’ {type(sub_exc).__name__}: {str(sub_exc)}\")\n",
    "        else:\n",
    "            print(f\"  â†’ {str(e)}\")\n",
    "\n",
    "await test_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Advantages\n",
    "\n",
    "### 1. **Autonomous Research**\n",
    "The agent independently decides what to search and which pages to scrape\n",
    "\n",
    "### 2. **Schema-Driven Extraction**\n",
    "Define your data structure once, get consistent JSON output\n",
    "\n",
    "### 3. **Enterprise-Grade Infrastructure**\n",
    "- Bright Data's global proxy network\n",
    "- Anti-bot detection bypass\n",
    "- Geo-targeting capabilities\n",
    "- 99.99% uptime SLA\n",
    "\n",
    "### 4. **Production Ready**\n",
    "- Asynchronous execution\n",
    "- Error handling built-in\n",
    "- Scalable architecture\n",
    "- MCP standardization\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                   LangGraph Agent                   â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚\n",
    "â”‚  â”‚ Claude LLM   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤  Agent Reasoning     â”‚ â”‚\n",
    "â”‚  â”‚ (Sonnet 4)   â”‚         â”‚  - Plan research     â”‚ â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  - Choose tools      â”‚ â”‚\n",
    "â”‚         â”‚                 â”‚  - Extract data      â”‚ â”‚\n",
    "â”‚         â–¼                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚\n",
    "â”‚  â”‚  Tool Node   â”‚                                  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "          â”‚\n",
    "          â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚         Bright Data MCP (Remote SSE)                â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚ search_engineâ”‚  â”‚ scrape_as_  â”‚  â”‚ web_data_ â”‚  â”‚\n",
    "â”‚  â”‚              â”‚  â”‚ markdown    â”‚  â”‚ * tools   â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "          â”‚\n",
    "          â–¼\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚          Bright Data Infrastructure                 â”‚\n",
    "â”‚  â€¢ 72M+ residential IPs                             â”‚\n",
    "â”‚  â€¢ Global geo-targeting                             â”‚\n",
    "â”‚  â€¢ Automatic retries & rotation                     â”‚\n",
    "â”‚  â€¢ CAPTCHA solving                                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Scale**: Process batches of topics concurrently\n",
    "- **Customize**: Add domain-specific extraction logic\n",
    "- **Integrate**: Connect to your data pipeline\n",
    "- **Extend**: Add more MCP tools for LinkedIn, GitHub, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [Bright Data MCP Documentation](https://docs.brightdata.com/mcp)\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [Claude API Documentation](https://docs.anthropic.com/)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
