{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Powered Data Enrichment Agent\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates building an intelligent data enrichment agent using:\n",
    "\n",
    "- **LangGraph**: Agentic workflow orchestration\n",
    "- **Bright Data MCP**: Model Context Protocol integration for web data access\n",
    "- **Claude Sonnet 4**: Advanced reasoning and structured extraction\n",
    "\n",
    "### What This Agent Does\n",
    "\n",
    "1. Takes a research topic and JSON schema as input\n",
    "2. Autonomously searches the web using Bright Data's SERP API\n",
    "3. Scrapes relevant websites with anti-bot bypass\n",
    "4. Extracts and structures data matching your schema\n",
    "5. Returns validated JSON output\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langgraph langchain-openai langchain-mcp-adapters python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Environment Variables\n",
    "\n",
    "You'll need:\n",
    "- `BRIGHT_DATA_API_KEY`: Get from [Bright Data Dashboard](https://brightdata.com/cp/api_tokens)\n",
    "- `ANTHROPIC_API_KEY`: Get from [Anthropic Console](https://console.anthropic.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment configured\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Verify keys are set\n",
    "assert os.getenv(\"BRIGHT_DATA_API_KEY\"), \"BRIGHT_DATA_API_KEY not set\"\n",
    "assert os.getenv(\"ANTHROPIC_API_KEY\"), \"ANTHROPIC_API_KEY not set\"\n",
    "\n",
    "print(\"✓ Environment configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppress Verbose Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Logging configured\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import warnings\n",
    "\n",
    "logging.getLogger().addFilter(\n",
    "    lambda record: \"Failed to validate notification\" not in record.getMessage()\n",
    ")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Failed to validate notification.*\")\n",
    "\n",
    "print(\"✓ Logging configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Agent Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Agent State\n",
    "\n",
    "The state tracks:\n",
    "- Research topic\n",
    "- Target extraction schema\n",
    "- Conversation messages\n",
    "- Extracted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Agent state defined\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import asyncio\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Annotated, List, Optional\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "@dataclass\n",
    "class AgentState:\n",
    "    \"\"\"State for the enrichment agent.\"\"\"\n",
    "    topic: str\n",
    "    extraction_schema: dict[str, Any]\n",
    "    messages: Annotated[List[BaseMessage], add_messages] = field(default_factory=list)\n",
    "    info: Optional[dict[str, Any]] = None\n",
    "\n",
    "print(\"✓ Agent state defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. System Prompt\n",
    "\n",
    "Instructs the agent on its research capabilities and workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ System prompt configured\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a research agent. Your task is to gather information about a topic and extract structured data.\n",
    "\n",
    "You have access to these tools:\n",
    "- search_engine: Search the web for information (Google/Bing/Yandex)\n",
    "- scrape_as_markdown: Get content from a specific URL with bot detection bypass\n",
    "- web_data_* tools: Fast, reliable structured data extraction from major platforms\n",
    "- submit_info: Call this when you have gathered all the required information\n",
    "\n",
    "Research topic: {topic}\n",
    "\n",
    "Required information schema:\n",
    "{schema}\n",
    "\n",
    "Search for relevant information, scrape important pages, then call submit_info with the extracted data.\"\"\"\n",
    "\n",
    "print(\"✓ System prompt configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create the Agent Graph\n",
    "\n",
    "This builds the LangGraph workflow with:\n",
    "- MCP client connection to Bright Data\n",
    "- Claude LLM integration\n",
    "- Tool execution node\n",
    "- Conditional routing logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Agent graph builder defined\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "async def create_agent():\n",
    "    \"\"\"Create the enrichment agent graph.\"\"\"\n",
    "\n",
    "    # Configure MCP client\n",
    "    client = MultiServerMCPClient({\n",
    "        \"bright_data\": {\n",
    "            \"url\": f\"https://mcp.brightdata.com/sse?token={os.getenv('BRIGHT_DATA_API_KEY')}\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Get available tools from MCP\n",
    "    tools = await client.get_tools()\n",
    "    print(f\"✓ Connected to Bright Data MCP ({len(tools)} tools available)\")\n",
    "\n",
    "    # Initialize the model\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    "        openai_api_base=\"https://api.anthropic.com/v1\",\n",
    "        model_name=\"claude-sonnet-4-20250514\"\n",
    "    )\n",
    "\n",
    "    async def call_model(state: AgentState) -> dict:\n",
    "        \"\"\"Call the LLM to decide next action.\"\"\"\n",
    "        prompt = SYSTEM_PROMPT.format(\n",
    "            topic=state.topic,\n",
    "            schema=json.dumps(state.extraction_schema, indent=2)\n",
    "        )\n",
    "\n",
    "        # Build messages: system prompt as first human message, then conversation\n",
    "        messages = [HumanMessage(content=prompt)] + list(state.messages)\n",
    "\n",
    "        # Create dynamic submit_info tool based on schema\n",
    "        info_tool = {\n",
    "            \"name\": \"submit_info\",\n",
    "            \"description\": \"Submit the extracted information when done researching. Call this with the structured data matching the required schema.\",\n",
    "            \"parameters\": state.extraction_schema,\n",
    "        }\n",
    "\n",
    "        # Bind all tools including the dynamic info tool\n",
    "        model = llm.bind_tools(list(tools) + [info_tool])\n",
    "\n",
    "        response = await model.ainvoke(messages)\n",
    "\n",
    "        # Check if submitting info\n",
    "        info = None\n",
    "        if hasattr(response, 'tool_calls') and response.tool_calls:\n",
    "            for tc in response.tool_calls:\n",
    "                if tc[\"name\"] == \"submit_info\":\n",
    "                    info = tc[\"args\"]\n",
    "                    break\n",
    "\n",
    "        return {\"messages\": [response], \"info\": info}\n",
    "\n",
    "    def route(state: AgentState) -> str:\n",
    "        \"\"\"Route to next node based on last message.\"\"\"\n",
    "        # If we have extracted info, we're done\n",
    "        if state.info:\n",
    "            return \"__end__\"\n",
    "\n",
    "        # Check the last message\n",
    "        if not state.messages:\n",
    "            return \"agent\"\n",
    "\n",
    "        last_msg = state.messages[-1]\n",
    "\n",
    "        if isinstance(last_msg, AIMessage) and hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:\n",
    "            # Check if it's a submit_info call\n",
    "            for tc in last_msg.tool_calls:\n",
    "                if tc[\"name\"] == \"submit_info\":\n",
    "                    return \"__end__\"\n",
    "            # Otherwise, execute the tools\n",
    "            return \"tools\"\n",
    "\n",
    "        return \"agent\"\n",
    "\n",
    "    # Build graph\n",
    "    graph = StateGraph(AgentState)\n",
    "    graph.add_node(\"agent\", call_model)\n",
    "    graph.add_node(\"tools\", ToolNode(tools))\n",
    "    graph.add_edge(\"__start__\", \"agent\")\n",
    "    graph.add_conditional_edges(\"agent\", route)\n",
    "    graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    return graph.compile()\n",
    "\n",
    "print(\"✓ Agent graph builder defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Enrichment Function\n",
    "\n",
    "Simple API to run the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Enrichment function ready\n"
     ]
    }
   ],
   "source": [
    "async def enrich(topic: str, schema: dict) -> dict:\n",
    "    \"\"\"Run the enrichment agent.\"\"\"\n",
    "    agent = await create_agent()\n",
    "    result = await agent.ainvoke({\n",
    "        \"topic\": topic,\n",
    "        \"extraction_schema\": schema,\n",
    "    })\n",
    "    return result.get(\"info\", {})\n",
    "\n",
    "print(\"✓ Enrichment function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo: Extract Company Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Extraction Schema\n",
    "\n",
    "Specify exactly what information you want to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema defined:\n",
      "{\n",
      "  \"type\": \"object\",\n",
      "  \"properties\": {\n",
      "    \"company_name\": {\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"industry\": {\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"headquarters\": {\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"founded\": {\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"key_products\": {\n",
      "      \"type\": \"array\",\n",
      "      \"items\": {\n",
      "        \"type\": \"string\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"company_name\",\n",
      "    \"industry\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "company_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"company_name\": {\"type\": \"string\"},\n",
    "        \"industry\": {\"type\": \"string\"},\n",
    "        \"headquarters\": {\"type\": \"string\"},\n",
    "        \"founded\": {\"type\": \"string\"},\n",
    "        \"key_products\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "    },\n",
    "    \"required\": [\"company_name\", \"industry\"]\n",
    "}\n",
    "\n",
    "print(\"Schema defined:\")\n",
    "print(json.dumps(company_schema, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Agent\n",
    "\n",
    "Watch the agent autonomously research and extract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "  |     await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |   File \"/tmp/ipykernel_2712937/319134285.py\", line 1, in <module>\n",
      "  |     result = await enrich(\"Stripe payments company\", company_schema)\n",
      "  |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/tmp/ipykernel_2712937/1868289780.py\", line 3, in enrich\n",
      "  |     agent = await create_agent()\n",
      "  |             ^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/tmp/ipykernel_2712937/3043821972.py\", line 18, in create_agent\n",
      "  |     tools = await client.get_tools()\n",
      "  |             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/langchain_mcp_adapters/client.py\", line 197, in get_tools\n",
      "  |     tools_list = await asyncio.gather(*load_mcp_tool_tasks)\n",
      "  |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/langchain_mcp_adapters/tools.py\", line 478, in load_mcp_tools\n",
      "  |     async with create_session(\n",
      "  |   File \"/usr/lib/python3.11/contextlib.py\", line 210, in __aenter__\n",
      "  |     return await anext(self.gen)\n",
      "  |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/langchain_mcp_adapters/sessions.py\", line 404, in create_session\n",
      "  |     async with _create_sse_session(**params) as session:\n",
      "  |   File \"/usr/lib/python3.11/contextlib.py\", line 210, in __aenter__\n",
      "  |     return await anext(self.gen)\n",
      "  |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/langchain_mcp_adapters/sessions.py\", line 267, in _create_sse_session\n",
      "  |     async with (\n",
      "  |   File \"/usr/lib/python3.11/contextlib.py\", line 210, in __aenter__\n",
      "  |     return await anext(self.gen)\n",
      "  |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/mcp/client/sse.py\", line 63, in sse_client\n",
      "  |     async with anyio.create_task_group() as tg:\n",
      "  |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 783, in __aexit__\n",
      "  |     raise BaseExceptionGroup(\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    |     yield\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpx/_transports/default.py\", line 394, in handle_async_request\n",
      "    |     resp = await self._pool.handle_async_request(req)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    |     raise exc from None\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    |     response = await connection.handle_async_request(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n",
      "    |     raise exc\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 78, in handle_async_request\n",
      "    |     stream = await self._connect(request)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpcore/_async/connection.py\", line 156, in _connect\n",
      "    |     stream = await stream.start_tls(**kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpcore/_backends/anyio.py\", line 67, in start_tls\n",
      "    |     with map_exceptions(exc_map):\n",
      "    |   File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    |     self.gen.throw(typ, value, traceback)\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    |     raise to_exc(exc) from exc\n",
      "    | httpcore.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1016)\n",
      "    | \n",
      "    | The above exception was the direct cause of the following exception:\n",
      "    | \n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/mcp/client/sse.py\", line 69, in sse_client\n",
      "    |     async with aconnect_sse(\n",
      "    |   File \"/usr/lib/python3.11/contextlib.py\", line 210, in __aenter__\n",
      "    |     return await anext(self.gen)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpx_sse/_api.py\", line 74, in aconnect_sse\n",
      "    |     async with client.stream(method, url, headers=headers, **kwargs) as response:\n",
      "    |   File \"/usr/lib/python3.11/contextlib.py\", line 210, in __aenter__\n",
      "    |     return await anext(self.gen)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpx/_client.py\", line 1583, in stream\n",
      "    |     response = await self.send(\n",
      "    |                ^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpx/_client.py\", line 1629, in send\n",
      "    |     response = await self._send_handling_auth(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpx/_client.py\", line 1657, in _send_handling_auth\n",
      "    |     response = await self._send_handling_redirects(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpx/_client.py\", line 1694, in _send_handling_redirects\n",
      "    |     response = await self._send_single_request(request)\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpx/_client.py\", line 1730, in _send_single_request\n",
      "    |     response = await transport.handle_async_request(request)\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpx/_transports/default.py\", line 393, in handle_async_request\n",
      "    |     with map_httpcore_exceptions():\n",
      "    |   File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\n",
      "    |     self.gen.throw(typ, value, traceback)\n",
      "    |   File \"/home/meirk/BrightAI/Demos/workshop/.venv/lib/python3.11/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    |     raise mapped_exc(message) from exc\n",
      "    | httpx.ConnectError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1016)\n",
      "    +------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = await enrich(\"Stripe payments company\", company_schema)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTED INFORMATION\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Competitor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitor_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"competitors\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"market_position\": {\"type\": \"string\"},\n",
    "                    \"key_differentiator\": {\"type\": \"string\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"competitors\"]\n",
    "}\n",
    "\n",
    "result = await enrich(\"Stripe competitors in payment processing\", competitor_schema)\n",
    "\n",
    "print(\"\\nCompetitor Analysis:\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Product Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"product_name\": {\"type\": \"string\"},\n",
    "        \"category\": {\"type\": \"string\"},\n",
    "        \"key_features\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"pricing_model\": {\"type\": \"string\"},\n",
    "        \"target_audience\": {\"type\": \"string\"}\n",
    "    },\n",
    "    \"required\": [\"product_name\", \"category\"]\n",
    "}\n",
    "\n",
    "result = await enrich(\"Claude AI by Anthropic\", product_schema)\n",
    "\n",
    "print(\"\\nProduct Information:\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Advantages\n",
    "\n",
    "### 1. **Autonomous Research**\n",
    "The agent independently decides what to search and which pages to scrape\n",
    "\n",
    "### 2. **Schema-Driven Extraction**\n",
    "Define your data structure once, get consistent JSON output\n",
    "\n",
    "### 3. **Enterprise-Grade Infrastructure**\n",
    "- Bright Data's global proxy network\n",
    "- Anti-bot detection bypass\n",
    "- Geo-targeting capabilities\n",
    "- 99.99% uptime SLA\n",
    "\n",
    "### 4. **Production Ready**\n",
    "- Asynchronous execution\n",
    "- Error handling built-in\n",
    "- Scalable architecture\n",
    "- MCP standardization\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────┐\n",
    "│                   LangGraph Agent                   │\n",
    "│  ┌──────────────┐         ┌──────────────────────┐ │\n",
    "│  │ Claude LLM   │◄────────┤  Agent Reasoning     │ │\n",
    "│  │ (Sonnet 4)   │         │  - Plan research     │ │\n",
    "│  └──────┬───────┘         │  - Choose tools      │ │\n",
    "│         │                 │  - Extract data      │ │\n",
    "│         ▼                 └──────────────────────┘ │\n",
    "│  ┌──────────────┐                                  │\n",
    "│  │  Tool Node   │                                  │\n",
    "│  └──────┬───────┘                                  │\n",
    "└─────────┼───────────────────────────────────────────┘\n",
    "          │\n",
    "          ▼\n",
    "┌─────────────────────────────────────────────────────┐\n",
    "│         Bright Data MCP (Remote SSE)                │\n",
    "│  ┌──────────────┐  ┌─────────────┐  ┌───────────┐  │\n",
    "│  │ search_engine│  │ scrape_as_  │  │ web_data_ │  │\n",
    "│  │              │  │ markdown    │  │ * tools   │  │\n",
    "│  └──────────────┘  └─────────────┘  └───────────┘  │\n",
    "└─────────────────────────────────────────────────────┘\n",
    "          │\n",
    "          ▼\n",
    "┌─────────────────────────────────────────────────────┐\n",
    "│          Bright Data Infrastructure                 │\n",
    "│  • 72M+ residential IPs                             │\n",
    "│  • Global geo-targeting                             │\n",
    "│  • Automatic retries & rotation                     │\n",
    "│  • CAPTCHA solving                                  │\n",
    "└─────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Scale**: Process batches of topics concurrently\n",
    "- **Customize**: Add domain-specific extraction logic\n",
    "- **Integrate**: Connect to your data pipeline\n",
    "- **Extend**: Add more MCP tools for LinkedIn, GitHub, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [Bright Data MCP Documentation](https://docs.brightdata.com/mcp)\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [Claude API Documentation](https://docs.anthropic.com/)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
